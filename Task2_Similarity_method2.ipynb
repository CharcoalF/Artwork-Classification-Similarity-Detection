{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 107M/107M [00:32<00:00, 3.43MB/s] \n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742057642.393285 6758927 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M3 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1742057642.465932 6765302 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742057642.477523 6765302 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742057646.838639 6765306 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "与目标图片最相似的 5 张图片：\n",
      "ImgNationalGalleryOfArt/800px-Allan_Ramsay,_Lord_George_Villiers,_NGA_76122.jpg - 相似度: 0.4323\n",
      "ImgNationalGalleryOfArt/1024px-Attributed_to_Hugo_van_der_Goes,_Saint_George_and_the_Dragon,_NGA_39733.jpg - 相似度: 0.3980\n",
      "ImgNationalGalleryOfArt/After_Pietro_da_Cortona,_Masinissa_and_Sophonisba,_NGA_65744.jpg - 相似度: 0.3951\n",
      "ImgNationalGalleryOfArt/800px-After_Francesco_Salviati,_Saint_Peter,_NGA_11388 (1).jpg - 相似度: 0.3942\n",
      "ImgNationalGalleryOfArt/1280px-Arthur_B._Davies,_Seated_Nude_and_a_Foot,_probably_1920,_NGA_56982.jpg - 相似度: 0.3879\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "import mediapipe as mp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ======================\n",
    "# 1. 加载数据集 & 预处理\n",
    "# ======================\n",
    "\n",
    "# 设定数据集路径\n",
    "train_dir = 'ImgNationalGalleryOfArt'\n",
    "image_size = (224, 224)  # 统一尺寸\n",
    "batch_size = 32\n",
    "\n",
    "# 获取所有图片路径\n",
    "image_paths = [os.path.join(train_dir, fname) for fname in os.listdir(train_dir) if fname.endswith('.jpg')]\n",
    "\n",
    "# 预处理：归一化 & 颜色调整\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # 颜色抖动适应不同风格\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ======================\n",
    "# 2. 加载模型 (MTCNN, FaceNet, ResNet, Mediapipe)\n",
    "# ======================\n",
    "\n",
    "# 人脸检测\n",
    "mtcnn = MTCNN(keep_all=True)\n",
    "\n",
    "# 人脸特征提取 (FaceNet)\n",
    "facenet = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "# 整体风格特征提取 (ResNet50)\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()\n",
    "\n",
    "# 姿态估计 (Mediapipe)\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# ======================\n",
    "# 3. 特征提取函数\n",
    "# ======================\n",
    "\n",
    "def extract_face_features(image):\n",
    "    \"\"\" 提取人脸特征 \"\"\"\n",
    "    img_cvt = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    faces = mtcnn(img_cvt)  # 进行人脸检测\n",
    "    if faces is None:\n",
    "        return None  # 没检测到人脸，返回空\n",
    "    \n",
    "    # 取第一张脸（如果有多个）\n",
    "    face = faces[0].unsqueeze(0)\n",
    "    \n",
    "    # 提取特征\n",
    "    with torch.no_grad():\n",
    "        face_embedding = facenet(face)\n",
    "    \n",
    "    return face_embedding.numpy().flatten()\n",
    "\n",
    "def extract_pose_features(image):\n",
    "    \"\"\" 提取人体关键点特征 \"\"\"\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(img_rgb)\n",
    "    \n",
    "    if results.pose_landmarks:\n",
    "        keypoints = np.array([[lm.x, lm.y] for lm in results.pose_landmarks.landmark])\n",
    "        return keypoints.flatten()\n",
    "    \n",
    "    return None  # 没检测到人体，返回空\n",
    "\n",
    "def extract_image_features(image):\n",
    "    \"\"\" 提取整张图片的视觉特征 \"\"\"\n",
    "    img_resized = preprocess(Image.fromarray(image)).unsqueeze(0)  # 预处理\n",
    "    with torch.no_grad():\n",
    "        features = resnet_model(img_resized)\n",
    "    return features.numpy().flatten()\n",
    "\n",
    "# ======================\n",
    "# 4. 计算相似性\n",
    "# ======================\n",
    "\n",
    "def compute_similarity(feature1, feature2, method='cosine'):\n",
    "    \"\"\" 计算特征相似度 \"\"\"\n",
    "    if feature1 is None or feature2 is None:\n",
    "        return 0  # 没有匹配特征时返回 0 相似度\n",
    "\n",
    "    if method == 'cosine':\n",
    "        return 1 - cosine(feature1, feature2)  # 余弦相似度\n",
    "    elif method == 'euclidean':\n",
    "        return 1 / (1 + euclidean(feature1, feature2))  # 欧几里得距离，归一化\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported similarity method!\")\n",
    "\n",
    "# ======================\n",
    "# 5. 计算数据集中的相似度\n",
    "# ======================\n",
    "\n",
    "# 计算所有图片的特征\n",
    "image_features = []\n",
    "face_features = []\n",
    "pose_features = []\n",
    "\n",
    "for path in image_paths:\n",
    "    img = cv2.imread(path)\n",
    "    \n",
    "    # 提取特征\n",
    "    image_feat = extract_image_features(img)\n",
    "    face_feat = extract_face_features(img)\n",
    "    pose_feat = extract_pose_features(img)\n",
    "    \n",
    "    image_features.append(image_feat)\n",
    "    face_features.append(face_feat)\n",
    "    pose_features.append(pose_feat)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "image_features = np.array(image_features)\n",
    "face_features = np.array(face_features, dtype=object)  # 可能有 None 值\n",
    "pose_features = np.array(pose_features, dtype=object)\n",
    "\n",
    "# ======================\n",
    "# 6. 评估相似性\n",
    "# ======================\n",
    "\n",
    "def find_most_similar(target_idx, top_k=5):\n",
    "    \"\"\" 在数据集中找到与目标图片最相似的前 K 张 \"\"\"\n",
    "    target_img_feat = image_features[target_idx]\n",
    "    target_face_feat = face_features[target_idx]\n",
    "    target_pose_feat = pose_features[target_idx]\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(len(image_paths)):\n",
    "        if i == target_idx:\n",
    "            continue\n",
    "        \n",
    "        img_sim = compute_similarity(target_img_feat, image_features[i], method='cosine')\n",
    "        face_sim = compute_similarity(target_face_feat, face_features[i], method='cosine')\n",
    "        pose_sim = compute_similarity(target_pose_feat, pose_features[i], method='euclidean')\n",
    "        \n",
    "        # 计算综合相似度 (加权平均)\n",
    "        total_sim = (0.5 * img_sim) + (0.3 * face_sim) + (0.2 * pose_sim)\n",
    "        similarities.append((image_paths[i], total_sim))\n",
    "    \n",
    "    # 排序并返回最相似的 top_k 图片\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]\n",
    "\n",
    "# 测试：查询某张图的相似结果\n",
    "query_idx = 10  # 任选一张图片\n",
    "similar_images = find_most_similar(query_idx)\n",
    "\n",
    "print(\"与目标图片最相似的 5 张图片：\")\n",
    "for img_path, sim_score in similar_images:\n",
    "    print(f\"{img_path} - 相似度: {sim_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ConvLSTM2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Model\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import normalize\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist # 创建函数来查找测试图像的最近邻\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import types\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None  # 取消大小限制\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import torch\n",
    "import cv2\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from torchvision import models, transforms\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置路径和参数\n",
    "train_dir = 'ImgNationalGalleryOfArt'\n",
    "image_size = (64, 64)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 载入数据\n",
    "def load_images(train_dir, image_size=(64, 64)):\n",
    "    image_paths = [os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.endswith('.jpg')]\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = load_img(path, target_size=image_size)\n",
    "        img = img_to_array(img) / 255.0  # 归一化\n",
    "        images.append(img)\n",
    "    return np.array(images), image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 目标检测（YOLOv5 检测人物）\n",
    "def detect_person(image):\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "    results = model(image)\n",
    "    results.render()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 姿态估计（Mediapipe）\n",
    "def extract_pose(image):\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(img_rgb)\n",
    "    if results.pose_landmarks:\n",
    "        return np.array([[lm.x, lm.y] for lm in results.pose_landmarks.landmark])\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CNN 特征提取（ResNet50）\n",
    "def extract_features(image):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img_resized = preprocess(image).unsqueeze(0)  \n",
    "    resnet_model = models.resnet50(pretrained=True)\n",
    "    resnet_model.eval()\n",
    "    with torch.no_grad():\n",
    "        features = resnet_model(img_resized)\n",
    "    return features.numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 计算相似度（Cosine Similarity）\n",
    "def compute_similarity(features1, features2):\n",
    "    return 1 - cosine(features1, features2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/bocongzhao/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:20<00:00, 5.03MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.7652250109297196\n"
     ]
    }
   ],
   "source": [
    "# 示例\n",
    "train_dir = 'ImgNationalGalleryOfArt'\n",
    "images, paths = load_images(train_dir)\n",
    "\n",
    "# 取两张图进行比较\n",
    "image1 = cv2.imread(paths[0])\n",
    "image2 = cv2.imread(paths[1])\n",
    "\n",
    "# 提取特征\n",
    "feat1 = extract_features(image1)\n",
    "feat2 = extract_features(image2)\n",
    "\n",
    "# 计算相似度\n",
    "similarity = compute_similarity(feat1, feat2)\n",
    "print(f\"Cosine Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载图片数量: 64\n"
     ]
    }
   ],
   "source": [
    "# 设置路径和参数\n",
    "train_dir = 'ImgNationalGalleryOfArt'\n",
    "image_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "# 获取所有图片路径\n",
    "image_paths = [os.path.join(train_dir, fname) for fname in os.listdir(train_dir) if fname.endswith('.jpg')]\n",
    "\n",
    "# 手动加载图片并转成数组\n",
    "images = []\n",
    "for path in image_paths:\n",
    "    img = load_img(path, target_size=image_size)  # 调整图片大小\n",
    "    img = img_to_array(img) / 255.0  # 转为数组并归一化\n",
    "    images.append(img)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "images = np.array(images)\n",
    "\n",
    "# 使用 flow 方法创建生成器\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30, # 随机旋转\n",
    "    width_shift_range=0.2, # 水平平移\n",
    "    height_shift_range=0.2, # 垂直平移\n",
    "    shear_range=0.2, # 随机错切变换\n",
    "    zoom_range=0.2, # 随机缩放\n",
    "    horizontal_flip=True # 随机水平翻转\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow(\n",
    "    images, # 数据集路径\n",
    "    batch_size=batch_size,  # 批量大小\n",
    "    shuffle=True, # 是否打乱数据，通常无监督学习需要打乱\n",
    "    #class_mode=None        # 无监督学习不需要标签\n",
    ")\n",
    "\n",
    "print(f'已加载图片数量: {len(images)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
